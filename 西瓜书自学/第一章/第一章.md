## 基本术语：
### 1.
* 数据集：data set(记录的集合)
* 示例:instance/样本:sample(每一条记录)
* 属性:attribute/特征:feature(反映事件或对象在某方面的特征)
* 属性值:attribute value(属性的取值)
* 属性空间:attribute space/样本空间:sample space(属性长成的空间，每个样本点在空间对应一个坐标向量，也把示例成为特征向量)
### 2.
$$D=\{x_1,x_2,\dots,x_m\}表示m个示例的数据集，每个示例由d个属性描述，则每个示例\\
x_i=(x_{i1},x_{i2},\cdots,x_{id})是d维样本空间X的一个向量,x_i\in X,x_{ij}是x_i在第j个属性上的取值，d称为样本x_i的维数
$$
### 3.
* 学习:learning/训练:training(从数据中学得模型)
* 训练数据:training data(训练过程使用的数据,其中每个样本为训练样本training sample,训练样本组成的集合为训练集training set)
* 假设hypothesis(学得模型对应了关于数据的某种潜在的规律)
* 真实:ground-truth(潜在规律自身)
* 学习器:learner(模型)f
* 标记:label(示例结果的信息)
* 样例example(拥有了标记信息的样本)<font     color=red>样本(sample)不带标记</font>
     一般用$(x_i,y_i)$表示第i个样例，其中$y_i\in$ Y是示例$x_i$的标记，Y是所有标记的集合,称为标记空间或输出空间label space
* 分类:classification(预测的是离散值)
* 回归:regression(预测的是连续值)
* 二分类:binary classification(对只涉及两个类别的分类，一个为正类:positive class,一个为反类:negative class)
* 多分类:multi-class classification(涉及多个类别)
* 测试:testing(使用学得的模型进行预测的过程)
* 测试样本:testing sample(被预测的样本)
* 聚类:clustering(将训练集的样本分成若干组，每组称为一个簇cluster)
* 监督学习:supervised learning(训练数据有标记信息，如分类和回归)
* 无监督学习:unsupervised learning(训练数据无标记信息，如聚类)
* 泛化generalization能力(学得模型适用于新样本的能力)  
    假设样本空间全体样本服从一个未知的分布D,获得的每个样本都是独立地从这个分布上采样获得的，即独立同分布(independent and identically distributed i.i.d) 

## 假设空间
1. 可以把学习过程看做一个在所有假设组成的空间进行搜索的过程，搜索目标是找到与训练集匹配(fit)的假设
2. 可以有多个策略对假设空间进行搜索，如自顶向下，从一般到特殊，自底向上，从特殊到一般，搜索过程中不断删除与正例不一致的假设或与反例一致的假设
3. 可能有多个假设与训练集一致，即存在一个假设集合，称之为版本空间(version space)

## 归纳偏好：
### 概念：
由仅有的训练样本，无法断定版本空间中哪个假设更好，然而对一个具体的学习算法而言，必须要产生一个模型，这时偏好就会起到关键作用。机器学习过程中对某类型假设的偏好，称为归纳偏好(inductive bias)或简称偏好
### NLF定理：
所有问题出现机会相同、或所有问题等同重要的前提下，任何学习算法的期望性能相同。
——脱离具体问题，空泛谈论什么算法更好毫无意义。
